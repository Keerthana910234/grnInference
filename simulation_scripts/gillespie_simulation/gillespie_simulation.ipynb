{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for Gillespie simulations\n",
    "\n",
    "## Steps\n",
    "\n",
    "- Input\n",
    "  - Read the input matrix\n",
    "  - create reactions\n",
    "  - the update matrices\n",
    "- Generate the steady state distribution\n",
    "  - Every 300 time steps, give birth to a cell\n",
    "  - simulate the cells in parallel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import re\n",
    "import numba\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "from tqdm.auto import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.integrate import solve_ivp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the matrix\n",
    "def read_input_matrix(path_to_matrix):\n",
    "    \"\"\"\n",
    "    Reads the input matrix from the specified file path and counts number of genes.\n",
    "    \n",
    "    Parameters:\n",
    "    path_to_matrix (str): The file path to the input matrix.\n",
    "    \n",
    "    Returns:\n",
    "    tuple:\n",
    "        n_genes (int): number of genes (matrix rows)\n",
    "        matrix (np.ndarray): internaction matrix (n_genes x n_genes)\n",
    "    \"\"\"\n",
    "    matrix = np.loadtxt(path_to_matrix, dtype='i', delimiter=',')\n",
    "    if matrix.ndim == 0:\n",
    "        matrix = np.array([[matrix]])\n",
    "\n",
    "    # print(type(matrix))\n",
    "    # print(matrix.shape)\n",
    "    return matrix.shape[0], matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_reaction_network_from_matrix(interaction_matrix):\n",
    "    \"\"\"\n",
    "    Generate a reaction DataFrame directly from a signed interaction matrix.\n",
    "    Assumes gene-specific parameters and interaction-specific regulation.\n",
    "\n",
    "    Args:\n",
    "        interaction_matrix (np.ndarray): shape (n_genes, n_genes)\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: reactions\n",
    "        List[str]: gene names\n",
    "    \"\"\"\n",
    "    n_genes = interaction_matrix.shape[0]\n",
    "    gene_list = [f\"gene_{i+1}\" for i in range(n_genes)]\n",
    "\n",
    "    prop = {\n",
    "        \"regulatory\": \"(({sign}*{p_add})*({activator}_protein**{n})/({k}**{n} + {activator}_protein**{n}))*{target}_I\",\n",
    "        \"activation\": \"{p_on}*{target}_I\",\n",
    "        \"inactivation\": \"{p_off}*{target}_A\",\n",
    "        \"mRNA_prod\": \"{p_prod_mRNA}*{target}_A\",\n",
    "        \"mRNA_deg\": \"{p_deg_mRNA}*{target}_mRNA\",\n",
    "        \"protein_prod\": \"{p_prod_protein}*{target}_mRNA\",\n",
    "        \"protein_deg\": \"{p_deg_protein}*{target}_protein\"\n",
    "    }\n",
    "\n",
    "    reactions = []\n",
    "\n",
    "    for j, target_gene in enumerate(gene_list):\n",
    "        param = lambda p: f\"{{{p}_{target_gene}}}\"\n",
    "\n",
    "        # Activation (gene_I → gene_A)\n",
    "        expr = prop[\"activation\"]\n",
    "        expr = expr.replace(\"{p_on}\", param(\"p_on\")).replace(\"{target}\", target_gene)\n",
    "        reactions.append({\n",
    "            \"species1\": f\"{target_gene}_A\", \"change1\": 1,\n",
    "            \"species2\": f\"{target_gene}_I\", \"change2\": -1,\n",
    "            \"propensity\": expr, \"time\": \"-\"\n",
    "        })\n",
    "\n",
    "        # Regulation by other genes (column j)\n",
    "        regulators = np.where(interaction_matrix[:, j] != 0)[0]\n",
    "        for i in regulators:\n",
    "            source_gene = gene_list[i]\n",
    "            sign = int(np.sign(interaction_matrix[i, j]))\n",
    "            edge_tag = f\"{source_gene}_to_{target_gene}\"\n",
    "\n",
    "            expr = prop[\"regulatory\"]\n",
    "            expr = expr.replace(\"{sign}\", str(sign))\n",
    "            expr = expr.replace(\"{p_add}\", f\"{{p_add_{edge_tag}}}\")\n",
    "            expr = expr.replace(\"{n}\", f\"{{n_{edge_tag}}}\")\n",
    "            expr = expr.replace(\"{k}\", f\"{{k_{edge_tag}}}\")\n",
    "            expr = expr.replace(\"{activator}\", source_gene)\n",
    "            expr = expr.replace(\"{target}\", target_gene)\n",
    "\n",
    "            reactions.append({\n",
    "                \"species1\": f\"{target_gene}_A\", \"change1\": 1,\n",
    "                \"species2\": f\"{target_gene}_I\", \"change2\": -1,\n",
    "                \"propensity\": expr, \"time\": \"-\"\n",
    "            })\n",
    "\n",
    "        # Inactivation (gene_A → gene_I)\n",
    "        expr = prop[\"inactivation\"]\n",
    "        expr = expr.replace(\"{p_off}\", param(\"p_off\")).replace(\"{target}\", target_gene)\n",
    "        reactions.append({\n",
    "            \"species1\": f\"{target_gene}_I\", \"change1\": 1,\n",
    "            \"species2\": f\"{target_gene}_A\", \"change2\": -1,\n",
    "            \"propensity\": expr, \"time\": \"-\"\n",
    "        })\n",
    "\n",
    "        # Transcription & translation (uses gene-specific params)\n",
    "        for label, suffix, change in [\n",
    "            (\"mRNA_prod\", \"mRNA\", 1),\n",
    "            (\"mRNA_deg\", \"mRNA\", -1),\n",
    "            (\"protein_prod\", \"protein\", 1),\n",
    "            (\"protein_deg\", \"protein\", -1)\n",
    "        ]:\n",
    "            expr = prop[label].replace(\"{target}\", target_gene)\n",
    "            for p in [\"d\", \"p_prod_mRNA\", \"p_deg_mRNA\", \"p_prod_protein\", \"p_deg_protein\"]:\n",
    "                expr = expr.replace(f\"{{{p}}}\", param(p))\n",
    "            reactions.append({\n",
    "                \"species1\": f\"{target_gene}_{suffix}\", \"change1\": change,\n",
    "                \"species2\": \"-\", \"change2\": \"-\",\n",
    "                \"propensity\": expr, \"time\": \"-\"\n",
    "            })\n",
    "\n",
    "    # Consolidate reactions with same species1/species2/change values\n",
    "    df = pd.DataFrame(reactions)\n",
    "    df['propensity'] = df['propensity'].astype(str)\n",
    "    reactions_df = (\n",
    "        df.groupby(['species1', 'change1', 'species2', 'change2', 'time'])['propensity']\n",
    "          .agg(lambda x: ' + '.join(x))\n",
    "          .reset_index()\n",
    "    )\n",
    "    return reactions_df, gene_list\n",
    "\n",
    "def generate_initial_state_from_genes(gene_list):\n",
    "    \"\"\"\n",
    "    Generate an initial state where all genes are inactive and have zero mRNA/protein.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame with columns ['species', 'count']\n",
    "    \"\"\"\n",
    "    states = []\n",
    "    for gene in gene_list:\n",
    "        states.extend([\n",
    "            {\"species\": f\"{gene}_A\", \"count\": 0},\n",
    "            {\"species\": f\"{gene}_I\", \"count\": 1},\n",
    "            {\"species\": f\"{gene}_mRNA\", \"count\": 0},\n",
    "            {\"species\": f\"{gene}_protein\", \"count\": 0}\n",
    "        ])\n",
    "    return pd.DataFrame(states)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_parameters_to_genes(csv_path, n_genes, rows=None):\n",
    "    \"\"\"\n",
    "    Assigns parameters from CSV to genes and returns a param_dict for expression substitution.\n",
    "    \n",
    "    Args:\n",
    "        csv_path (str): Path to parameter CSV file\n",
    "        rows (list of int, optional): Specific row indices to select. If None, selects randomly.\n",
    "        n_random (int): Number of random rows to select if rows is None.\n",
    "    \n",
    "    Returns:\n",
    "        tuple:\n",
    "            param_dict (dict): {\"{param_geneX}\": value}\n",
    "            param_matrix (pd.DataFrame): gene-wise parameter values\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path, index_col=0)\n",
    "\n",
    "    # Select rows to assign to genes\n",
    "    if rows is None:\n",
    "        rows = np.random.choice(df.index, size=n_genes, replace=True)\n",
    "\n",
    "    param_dict = {}\n",
    "    param_matrix = {}\n",
    "    row_mapping = {}\n",
    "\n",
    "    for i, row in enumerate(rows):\n",
    "        gene = f\"gene_{i+1}\"\n",
    "        values = df.loc[row].copy()\n",
    "        row_mapping[gene] = row\n",
    "\n",
    "        # Derived params\n",
    "        values[\"p_deg_mRNA\"] = np.log(2) / values[\"mrna_half_life\"]\n",
    "        values[\"p_deg_protein\"] = np.log(2) / values[\"protein_half_life\"]\n",
    "\n",
    "\n",
    "        # Remove unused columns\n",
    "        values.drop([\"mrna_half_life\", \"protein_half_life\", \"burst_size\"], inplace=True, errors=\"ignore\")\n",
    "\n",
    "        # Add to param_matrix\n",
    "        param_matrix[gene] = values\n",
    "\n",
    "        # Flatten into param_dict with curly-brace keys\n",
    "        for param, val in values.items():\n",
    "            param_dict[f\"{{{param}_{gene}}}\"] = val\n",
    "\n",
    "    param_matrix_df = pd.DataFrame(param_matrix).T\n",
    "    return param_dict, param_matrix_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An useful utility function that is not used for simulation\n",
    "# def calculate_unregulated_protein_levels(p_on, p_off, p_prod_mRNA, p_deg_mRNA, p_prod_protein, p_deg_protein, global_params=None):\n",
    "#     \"\"\"\n",
    "#     Calculate protein levels without any regulation (for comparison/initialization).\n",
    "    \n",
    "#     Args:\n",
    "#         param_matrix (pd.DataFrame): Gene parameters\n",
    "#         global_params (dict, optional): Global constants\n",
    "        \n",
    "#     Returns:\n",
    "#         np.ndarray: Unregulated steady-state protein levels\n",
    "#     \"\"\"    \n",
    "#     # Calculate unregulated levels\n",
    "#     burst_prob = p_on / (p_on + p_off)\n",
    "#     mRNA = p_prod_mRNA * burst_prob / (p_deg_mRNA)\n",
    "#     protein_levels = mRNA * p_prod_protein / p_deg_protein\n",
    "    # return protein_levels\n",
    "\n",
    "def generate_k_from_steady_state_calc(param_dict, interaction_matrix, gene_list,\n",
    "                                        global_params=None, target_hill=0.5, scale_k=None, verbose=False):\n",
    "    \"\"\"\n",
    "    Calculate steady-state protein levels using regulated k_on_eff for each gene,\n",
    "    and update EC50 (k_*) values only for actual regulatory edges.\n",
    "\n",
    "    Args:\n",
    "        param_dict (dict): Parameter dictionary with gene-specific and edge-specific entries.\n",
    "        interaction_matrix (np.ndarray): shape (n_genes, n_genes), effect of gene i on gene j.\n",
    "        gene_list (list): List of gene names in order.\n",
    "        global_params (dict): Optional global constants (unused).\n",
    "        target_hill (float): Hill output to match when computing EC50.\n",
    "        scale_k (np.ndarray or None): shape (n_genes, n_genes). scale_k[i, j] applies to k_{i→j}.\n",
    "                                      Defaults to 1.0 for all entries.\n",
    "        verbose (bool): Print debug info.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (np.ndarray of steady-state protein levels, updated param_dict with k_* entries)\n",
    "    \"\"\"\n",
    "    n_genes = len(gene_list)\n",
    "\n",
    "    if scale_k is None:\n",
    "        scale_k = np.ones((n_genes, n_genes))\n",
    "    else:\n",
    "        scale_k = np.asarray(scale_k)\n",
    "        assert scale_k.shape == (n_genes, n_genes), \"scale_k must be of shape (n_genes, n_genes)\"\n",
    "\n",
    "    protein_levels = np.zeros(n_genes)\n",
    "    p_on_eff = np.zeros(n_genes)\n",
    "\n",
    "    for i in range(n_genes):\n",
    "        gene = gene_list[i]\n",
    "        p_on = param_dict[f'{{p_on_{gene}}}']\n",
    "        p_off = param_dict[f'{{p_off_{gene}}}']\n",
    "        p_prod_mRNA = param_dict[f'{{p_prod_mRNA_{gene}}}']\n",
    "        p_deg_mRNA = param_dict[f'{{p_deg_mRNA_{gene}}}']\n",
    "        p_prod_protein = param_dict[f'{{p_prod_protein_{gene}}}']\n",
    "        p_deg_protein = param_dict[f'{{p_deg_protein_{gene}}}']\n",
    "\n",
    "\n",
    "        # Sum regulatory contributions\n",
    "        regulatory_effect = 0.0\n",
    "        regulators = np.where(interaction_matrix[:, i] != 0)[0]\n",
    "\n",
    "        for reg in regulators:\n",
    "            #Fix: Can be more precise than this estimation?\n",
    "            source = gene_list[reg]\n",
    "            edge = f\"{source}_to_{gene}\"\n",
    "            print(param_dict)\n",
    "            p_add = param_dict.get(f\"{{p_add_{edge}}}\", 0)\n",
    "            sign = interaction_matrix[reg, i]\n",
    "            regulatory_effect += target_hill * p_add * sign\n",
    "            print(source, edge, p_add, sign, regulatory_effect)\n",
    "\n",
    "        p_on_eff[i] = p_on + regulatory_effect\n",
    "\n",
    "        # # Compute protein level using k_on_eff\n",
    "        burst_prob = p_on_eff[i] / (p_on_eff[i] + p_off)\n",
    "        mRNA = p_prod_mRNA * burst_prob / p_deg_mRNA\n",
    "        protein = mRNA * p_prod_protein / p_deg_protein\n",
    "\n",
    "        protein_levels[i] = max(protein, 0.1)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Gene {gene}: p_on = {p_on:.3f} → p_on_eff = {p_on_eff[i]:.3f} \" \n",
    "                  f\"(reg_effect: {regulatory_effect:.3f}) → Protein level: {protein_levels[i]:.3f}\")\n",
    "\n",
    "        # Assign EC50 values (k_*) only for actual edges, scaled with scale_k[i, j]\n",
    "    for i in range(n_genes):\n",
    "        source_gene = gene_list[i]\n",
    "        targets = np.where(interaction_matrix[i, :] != 0)[0]\n",
    "        for j in targets:\n",
    "            target_gene = gene_list[j]\n",
    "            key = f\"{{k_{source_gene}_to_{target_gene}}}\"\n",
    "            param_dict[key] = protein_levels[i] * scale_k[i, j]\n",
    "\n",
    "    return protein_levels, param_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_interaction_terms(param_dict, interaction_matrix, gene_list, n_matrix=None, p_add_matrix=None):\n",
    "    \"\"\"\n",
    "    Add n and p_add terms to param_dict based on interaction_matrix.\n",
    "    Also calculates EC50 (k) values using steady-state protein levels.\n",
    "\n",
    "    Args:\n",
    "        param_dict (dict): Initial dictionary of gene-specific parameters.\n",
    "        interaction_matrix (np.ndarray): Regulatory interactions (2D array).\n",
    "        gene_list (list): List of gene names like ['gene_1', 'gene_2', ...].\n",
    "        n_matrix (np.ndarray, optional): Matrix of Hill coefficients (defaults to 2).\n",
    "        p_add_matrix (np.ndarray, optional): Matrix of r_add values (defaults to 10).\n",
    "\n",
    "    Returns:\n",
    "       tuple:\n",
    "        protein_levels (np.ndarray): Estimated steady-state protein levels\n",
    "        param_dict_updated (dict): Updated dictionary with added n, p_add, and k values\n",
    "    \"\"\"\n",
    "    interaction_matrix = np.array(interaction_matrix)\n",
    "    n_genes = len(gene_list)\n",
    "    param_dict_updated = param_dict.copy()\n",
    "    if n_matrix is None:\n",
    "        n_matrix = np.full((n_genes, n_genes), 2)\n",
    "    if p_add_matrix is None:\n",
    "        p_add_matrix = np.full((n_genes, n_genes), 10)\n",
    "\n",
    "    for i in range(n_genes):\n",
    "        for j in range(n_genes):\n",
    "            if interaction_matrix[i, j] != 0:\n",
    "                gene_i = gene_list[i]\n",
    "                gene_j = gene_list[j]\n",
    "                edge = f\"{gene_i}_to_{gene_j}\"\n",
    "\n",
    "                param_dict_updated[f\"{{n_{edge}}}\"] = n_matrix[i, j]\n",
    "                param_dict_updated[f\"{{p_add_{edge}}}\"] = p_add_matrix[i, j]\n",
    "    # Generate EC50 values using the correct steady-state calculation\n",
    "    protein_levels, k_dict = generate_k_from_steady_state_calc(param_dict_updated, interaction_matrix, gene_list)\n",
    "\n",
    "    return protein_levels, k_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_gillespie_params_from_reactions(init_states, reactions, param_dictionary):\n",
    "    \"\"\"\n",
    "    Setup Gillespie update matrix and function using species and parameter templates.\n",
    "\n",
    "    Args:\n",
    "        init_states (pd.DataFrame): columns ['species', 'count']\n",
    "        reactions (pd.DataFrame): columns ['species1', 'change1', 'species2', 'change2', 'propensity', 'time']\n",
    "        param_dictionary (dict): Dictionary containing all parameters (e.g., p_on_*, k_*, p_add_*, ...)\n",
    "\n",
    "    Returns:\n",
    "        population_init (np.ndarray), update_matrix (np.ndarray), update_function (str), species_index (dict)\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If any required placeholder in reaction propensities is not in param_dictionary.\n",
    "    \"\"\"\n",
    "    init_states = init_states.dropna()\n",
    "    reactions = reactions.dropna()\n",
    "\n",
    "    species_index = {s: i for i, s in enumerate(init_states['species'])}\n",
    "    population_init = init_states['count'].values.astype(np.int64)\n",
    "    \n",
    "    update_matrix = []\n",
    "    propensity_formulas = []\n",
    "    missing_keys_report = []\n",
    "\n",
    "    for i, row in reactions.iterrows():\n",
    "        delta = [0] * len(species_index)\n",
    "        if row['species1'] not in species_index:\n",
    "            raise ValueError(f\"Species1 {row['species1']} not in speciesIndex\")\n",
    "        delta[species_index[row['species1']]] = int(row['change1'])\n",
    "        \n",
    "        if row['species2'] != '-':\n",
    "            delta[species_index[row['species2']]] = int(row['change2'])\n",
    "            if row['species2'] not in species_index:\n",
    "                raise ValueError(f\"Species2 {row['species2']} not in speciesIndex\")\n",
    "        update_matrix.append(delta)\n",
    "\n",
    "        expr = row['propensity']\n",
    "\n",
    "        # Replace species with indexed population\n",
    "        for species, idx in species_index.items():\n",
    "            expr = expr.replace(species, f\"population[{idx}]\")\n",
    "\n",
    "        # Validate and inject all parameter placeholders\n",
    "        placeholders = set(re.findall(r\"{[^}]+}\", expr))\n",
    "        missing = placeholders - set(param_dictionary.keys())\n",
    "        if missing:\n",
    "            missing_keys_report.append((i, row['propensity'], list(missing)))\n",
    "            continue  # move to next reaction without injecting\n",
    "\n",
    "        for key, val in param_dictionary.items():\n",
    "            expr = expr.replace(key, str(val))\n",
    "\n",
    "        if row['time'] != '-':\n",
    "            line = f\"propensities[{i}] = ({expr}) if ({row['time']}) else 0\"\n",
    "        else:\n",
    "            line = f\"propensities[{i}] = {expr}\"\n",
    "        propensity_formulas.append(line)\n",
    "\n",
    "    if missing_keys_report:\n",
    "        error_message = \"Missing parameters in propensity expressions:\\n\"\n",
    "        for i, raw_expr, missing_keys in missing_keys_report:\n",
    "            error_message += f\"  [Reaction {i}] '{raw_expr}' is missing: {', '.join(missing_keys)}\\n\"\n",
    "        raise ValueError(error_message)\n",
    "\n",
    "    update_func = \"import numba\\nimport numpy as np\\n@numba.njit(fastmath=True)\\ndef update_propensities(propensities, population, t):\\n\\t\" + \"\\n\\t\".join(propensity_formulas)\n",
    "\n",
    "    return population_init, np.array(update_matrix, dtype=np.int64), update_func, species_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_discrete(probs): #samples which reaction to run next\n",
    "    \"\"\"Randomly sample an index with probability given by probs.\"\"\"\n",
    "    # Generate random number\n",
    "    q = np.random.rand()\n",
    "\n",
    "    # Find index\n",
    "    i = 0\n",
    "    p_sum = 0.0\n",
    "    while p_sum < q:\n",
    "        p_sum += probs[i]\n",
    "        i += 1\n",
    "    return i - 1\n",
    "\n",
    "def gillespie_draw(propensity_func, propensities, population, t):\n",
    "    \"\"\"\n",
    "    Draws a reaction and the time it took to do that reaction.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    propensity_func : function\n",
    "        Function with call signature propensity_func(population, t, *args)\n",
    "        used for computing propensities. This function must return\n",
    "        an array of propensities.\n",
    "    propensities : ndarray\n",
    "        Propensities for each reaction as a 1D Numpy array.\n",
    "    population : ndarray\n",
    "        Current population of particles (key entities of interest, ie TF(RNA), TF(P))\n",
    "    t : float\n",
    "        Value of the current time.\n",
    "    args : tuple, default ()\n",
    "        Arguments to be passed to `propensity_func`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    rxn : int\n",
    "        Index of reaction that occured.\n",
    "    time : float\n",
    "        Time it took for the reaction to occur.\n",
    "    \"\"\"\n",
    "    # Compute propensities\n",
    "    propensity_func(propensities, population, t)\n",
    "\n",
    "    # Sum of propensities\n",
    "    props_sum = propensities.sum()\n",
    "    if props_sum <= 0:\n",
    "        return -1, -1  # or some sentinel\n",
    "    # Compute next time\n",
    "    time = np.random.exponential(1.0 / props_sum) ## exponentially distributed state-switching\n",
    "\n",
    "    # Compute discrete probabilities of each reaction\n",
    "    rxn_probs = propensities / props_sum\n",
    "\n",
    "    # Draw reaction from this distribution\n",
    "    rxn = sample_discrete(rxn_probs) #sample_discrete(rxn_probs) or sample_discrete_scipy(rxn_probs)\n",
    "\n",
    "    return rxn, time\n",
    "\n",
    "def gillespie_ssa(propensity_func, update, population_0, time_points):\n",
    "    \"\"\"\n",
    "    Uses the Gillespie stochastic simulation algorithm to sample\n",
    "    from probability distribution of particle counts over time.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    propensity_func : function\n",
    "        Function of the form f(params, t, population) that takes the current\n",
    "        population of particle counts and returns an array of propensities\n",
    "        for each reaction.\n",
    "    update : ndarray, shape (num_reactions, num_chemical_species)\n",
    "        Entry i, j gives the change in particle counts of species j\n",
    "        for chemical reaction i.\n",
    "    population_0 : array_like, shape (num_chemical_species)\n",
    "        Array of initial populations of all chemical species.\n",
    "    time_points : array_like, shape (num_time_points,)\n",
    "        Array of points in time for which to sample the probability\n",
    "        distribution.\n",
    "    args : tuple, default ()\n",
    "        The set of parameters to be passed to propensity_func.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sample : ndarray, shape (num_time_points, num_chemical_species)\n",
    "        Entry i, j is the count of chemical species j at time\n",
    "        time_points[i].\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize output\n",
    "    pop_out = np.empty((len(time_points), update.shape[1]), dtype=np.int64)\n",
    "\n",
    "    # Initialize and perform simulation\n",
    "    i_time = 1\n",
    "    i = 0\n",
    "    t = time_points[0]\n",
    "    population = population_0.copy()\n",
    "    pop_out[0, :] = population\n",
    "    propensities = np.zeros(update.shape[0])\n",
    "    while i < len(time_points):\n",
    "        while t < time_points[i_time]:\n",
    "            # draw the event and time step\n",
    "            event, dt = gillespie_draw(propensity_func, propensities, population, t)\n",
    "            if event == -1 and dt == -1:\n",
    "                raise ValueError(\"Propensity sum was 0 or negative!\")\n",
    "            # Update the population\n",
    "            population_previous = population.copy()\n",
    "            population += update[event, :]\n",
    "\n",
    "            # Increment time\n",
    "            t += dt\n",
    "\n",
    "        # Update the index\n",
    "        i = np.searchsorted(time_points > t, True)\n",
    "\n",
    "        # Update the population\n",
    "        pop_out[i_time : min(i, len(time_points))] = population_previous\n",
    "\n",
    "        # Increment index\n",
    "        i_time = i\n",
    "\n",
    "    return pop_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mrna_protein(samples, species_index, types=('mRNA', 'protein')):\n",
    "    \"\"\"\n",
    "    Extract mRNA/protein data from a 3D samples array: (n_cells, n_timepoints, n_species)\n",
    "    \n",
    "    Args:\n",
    "        samples (np.ndarray): shape (n_cells, n_timepoints, n_species)\n",
    "        species_index (dict): species name → index\n",
    "        types (tuple): which species types to include\n",
    "    Returns:\n",
    "        pd.DataFrame\n",
    "    \"\"\"\n",
    "    n_cells, n_timepoints, _ = samples.shape\n",
    "    selected_species = {k: v for k, v in species_index.items() if any(k.endswith(t) for t in types)}\n",
    "    \n",
    "    records = []\n",
    "    for cell in range(n_cells):\n",
    "        for tp in range(n_timepoints):\n",
    "            row = {'cell_id': cell, 'time_step': tp}\n",
    "            for species, idx in selected_species.items():\n",
    "                row[species] = samples[cell, tp, idx]\n",
    "            records.append(row)\n",
    "    df = pd.DataFrame.from_records(records)\n",
    "    df.attrs['units'] = {\n",
    "       'time_step': 'hours',          \n",
    "       'cell_id': 'unitless',\n",
    "       **{species: 'molecule count' for species in selected_species}\n",
    "    }\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steady state test calculations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grn_ode(t, y, params, p_on_eff=None):\n",
    "    # Unpack species\n",
    "    gene_1_A, gene_1_I, mRNA_1, protein_1, gene_2_A, gene_2_I, mRNA_2, protein_2 = y\n",
    "\n",
    "    # Unpack parameters\n",
    "    p_on_1 = params['{p_on_gene_1}']\n",
    "    p_off_1 = params['{p_off_gene_1}']\n",
    "    p_prod_mRNA_1 = params['{p_prod_mRNA_gene_1}']\n",
    "    p_deg_mRNA_1 = params['{p_deg_mRNA_gene_1}']\n",
    "    p_prod_protein_1 = params['{p_prod_protein_gene_1}']\n",
    "    p_deg_protein_1 = params['{p_deg_protein_gene_1}']\n",
    "\n",
    "    p_on_2 = params['{p_on_gene_2}']\n",
    "    p_off_2 = params['{p_off_gene_2}']\n",
    "    p_prod_mRNA_2 = params['{p_prod_mRNA_gene_2}']\n",
    "    p_deg_mRNA_2 = params['{p_deg_mRNA_gene_2}']\n",
    "    p_prod_protein_2 = params['{p_prod_protein_gene_2}']\n",
    "    p_deg_protein_2 = params['{p_deg_protein_gene_2}']\n",
    "\n",
    "    r_add = params['{p_add_gene_1_to_gene_2}']\n",
    "    n = params['{n_gene_1_to_gene_2}']\n",
    "    k = params['{k_gene_1_to_gene_2}']\n",
    "\n",
    "    # Hill function (if p_on_eff is not provided)\n",
    "    if p_on_eff is None:\n",
    "        hill = (r_add * (protein_1**n)) / (k**n + protein_1**n)\n",
    "        p_on2_eff = p_on_2 + hill\n",
    "    else:\n",
    "        p_on2_eff = p_on_eff\n",
    "\n",
    "    # ODEs\n",
    "    d_gene_1_A = -p_off_1 * gene_1_A + p_on_1 * gene_1_I\n",
    "    d_gene_1_I = -d_gene_1_A\n",
    "\n",
    "    d_mRNA_1 = p_prod_mRNA_1 * gene_1_A - p_deg_mRNA_1 * mRNA_1\n",
    "    d_protein_1 = p_prod_protein_1 * mRNA_1 - p_deg_protein_1 * protein_1\n",
    "\n",
    "    d_gene_2_A = -p_off_2 * gene_2_A + p_on2_eff * gene_2_I\n",
    "    d_gene_2_I = -d_gene_2_A\n",
    "\n",
    "    d_mRNA_2 = p_prod_mRNA_2 * gene_2_A - p_deg_mRNA_2 * mRNA_2\n",
    "    d_protein_2 = p_prod_protein_2 * mRNA_2 - p_deg_protein_2 * protein_2\n",
    "\n",
    "    return [\n",
    "        d_gene_1_A, d_gene_1_I, d_mRNA_1, d_protein_1,\n",
    "        d_gene_2_A, d_gene_2_I, d_mRNA_2, d_protein_2\n",
    "    ]\n",
    "\n",
    "def compute_effective_kon(df, param_dict):\n",
    "    protein1 = df['gene_1_protein'].values\n",
    "    n = float(param_dict['{n_gene_1_to_gene_2}'])\n",
    "    k = float(param_dict['{k_gene_1_to_gene_2}'])\n",
    "    p_add = float(param_dict['{p_add_gene_1_to_gene_2}'])\n",
    "    p_on = float(param_dict['{p_on_gene_2}'])\n",
    "\n",
    "    hill_vals = (protein1 ** n) / (k**n + protein1 ** n)\n",
    "    return p_on + p_add * np.mean(hill_vals)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_matrix = \"/home/mzo5929/Keerthana/grnInference/simulation_data/general_simulation_data/test_data/matrix101.txt\"\n",
    "n_genes, interaction_matrix = read_input_matrix(path_to_matrix)\n",
    "interaction_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reactions_df, gene_list = generate_reaction_network_from_matrix(interaction_matrix=interaction_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_states = generate_initial_state_from_genes(gene_list=gene_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_path = \"/home/mzo5929/Keerthana/grnInference/simulation_data/general_simulation_data/test_data/parameter_sheet_gillespie.csv\"\n",
    "rows = [12, 13]\n",
    "param_dict, param_df = assign_parameters_to_genes(param_path, gene_list, rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_add_matrix = np.array([\n",
    "    [0.0, 2.0],  # gene_1 effects\n",
    "    [0, 0]  # gene_2 effects\n",
    "])\n",
    "\n",
    "n_matrix = np.array([\n",
    "    [0.0, 4.4118197399108965],  # gene_1 effects\n",
    "    [0, 0]  # gene_2 effects\n",
    "])\n",
    "\n",
    "steady_state, full_param_dict = add_interaction_terms(param_dict, interaction_matrix, gene_list, p_add_matrix=p_add_matrix, n_matrix = n_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steady_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_param_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_0, update_matrix, update_propensity_func_string, species_index = setup_gillespie_params_from_reactions(init_states, reactions_df, full_param_dict)\n",
    "exec(update_propensity_func_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Example parameters\n",
    "\n",
    "# # Initial conditions: all zeros except one active burst\n",
    "# y0 = population_0 # [A1, I1, m1, p1, A2, I2, m2, p2]\n",
    "\n",
    "# sim_Gillespie_10000_cells = pd.read_csv('/home/mzo5929/Keerthana/grnInference/simulation_data/gillespie_simulation/test/df_simulation_1000_cells_1000h_timepoints_rows_12_13_20250702_155737_89705a22.csv')\n",
    "# time = 999\n",
    "# singleTime_df_gillespie_10000 = sim_Gillespie_10000_cells[(sim_Gillespie_10000_cells['time_step'] == time)]\n",
    "# p_on_eff_gene_2 = compute_effective_kon(singleTime_df_gillespie_10000, full_param_dict)\n",
    "# protein1_samples = singleTime_df_gillespie_10000['gene_1_protein'].values\n",
    "# K = full_param_dict['{k_gene_1_to_gene_2}']\n",
    "# n = full_param_dict['{n_gene_1_to_gene_2}']\n",
    "# hill_vals = (protein1_samples ** n) / (K**n + protein1_samples ** n)\n",
    "# mean_hill = np.mean(hill_vals)\n",
    "# print(f\"Expected Hill output from simulation: {mean_hill:.4f}\")\n",
    "# hill_at_mean = (np.mean(protein1_samples) ** n) / (K**n + np.mean(protein1_samples) ** n)\n",
    "# print(f\"Hill(mean protein1): {hill_at_mean:.4f}\")\n",
    "\n",
    "\n",
    "# from functools import partial\n",
    "# from scipy.integrate import solve_ivp\n",
    "\n",
    "# wrapped_ode = partial(grn_ode, params=full_param_dict, p_on_eff=p_on_eff_gene_2)\n",
    "# sol = solve_ivp(wrapped_ode, [0, 1000], y0, method='RK45', dense_output=True)\n",
    "# sol['y'][:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed random number generator for reproducibility\n",
    "np.random.seed(42)\n",
    "n_gene = len(gene_list)\n",
    "n_cells = 10000\n",
    "time_duration = 200#in hours\n",
    "time_points = np.arange(0, time_duration, 1)\n",
    "# Initialize output array\n",
    "samples = np.empty((n_cells, len(time_points), n_gene*4), dtype=int)\n",
    "\n",
    "# Run the calculations\n",
    "# for i in tqdm(range(n_cells)):\n",
    "#     samples[i, :, :] = gillespie_ssa(update_propensities, update_matrix, population_0, time_points)\n",
    "    \n",
    "\n",
    "\n",
    "# Your original variables\n",
    "# samples: shape (n_cells, len(time_points), num_species)\n",
    "samples = np.zeros((n_cells, len(time_points), population_0.shape[0]))\n",
    "\n",
    "def run_simulation(i):\n",
    "    return gillespie_ssa(update_propensities, update_matrix, population_0, time_points)\n",
    "\n",
    "# Run in parallel with tqdm\n",
    "results = Parallel(n_jobs=8)(\n",
    "    delayed(run_simulation)(i) for i in tqdm(range(n_cells))\n",
    ")\n",
    "\n",
    "# # Store results into the samples array\n",
    "for i, res in enumerate(results):\n",
    "    samples[i, :, :] = res\n",
    "\n",
    "\n",
    "all_samples = extract_mrna_protein(samples, species_index)\n",
    "\n",
    "\n",
    "#code to reshape 3D to 2D and output + input: geeksforgeeks.org/how-to-load-and-save-3d-numpy-array-to-file-using-savetxt-and-loadtxt-functions/\n",
    "samples_reshaped = samples.reshape(samples.shape[0], -1)\n",
    "\n",
    "# === Setup ===\n",
    "now = datetime.now()\n",
    "timestamp_str = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "short_id = uuid.uuid4().hex[:8]\n",
    "row_str = \"_\".join(map(str, rows))\n",
    "prefix = f\"_{timestamp_str}_{n_cells}_cells_{time_duration}h_timepoints_rows_{row_str}_{short_id}\"\n",
    "\n",
    "base_path = \"/home/mzo5929/Keerthana/grnInference/simulation_data/gillespie_simulation/test\"\n",
    "jsonl_path = os.path.join(base_path, \"simulation_metadata.jsonl\")  # single file to append to\n",
    "\n",
    "# === File paths ===\n",
    "df_path = os.path.join(base_path, f\"df_simulation_{prefix}.csv\")\n",
    "samples_path = os.path.join(base_path, f\"samples_simulation_{prefix}.csv\")\n",
    "\n",
    "# === Save reshaped samples ===\n",
    "np.savetxt(samples_path, samples_reshaped, delimiter=\",\")\n",
    "\n",
    "# === Save DataFrame ===\n",
    "all_samples.to_csv(df_path, index=False)\n",
    "\n",
    "# === Prepare metadata record ===\n",
    "record = {\n",
    "    \"id\": short_id,\n",
    "    \"timestamp\": now.isoformat(),\n",
    "    \"param_dict\": param_dict,\n",
    "    \"interaction_matrix\": interaction_matrix.tolist(),\n",
    "    \"steady_state\": steady_state.tolist() if hasattr(steady_state, \"tolist\") else steady_state,\n",
    "    \"df_path\": df_path,\n",
    "    \"samples_path\": samples_path\n",
    "}\n",
    "\n",
    "# === Append to JSONL file ===\n",
    "with open(jsonl_path, 'a') as f:\n",
    "    f.write(json.dumps(record) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Updates\n",
    "# # Optimized Gillespie-SSA Simulation Pipeline\n",
    "\n",
    "import os\n",
    "import uuid\n",
    "import json\n",
    "from datetime import datetime\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numba\n",
    "from numba import prange\n",
    "\n",
    "# %% Input utilities\n",
    "\n",
    "def read_input_matrix(path_to_matrix: str) -> (int, np.ndarray):\n",
    "    matrix = np.loadtxt(path_to_matrix, dtype=int, delimiter=',')\n",
    "    if matrix.ndim == 0:\n",
    "        matrix = matrix.reshape((1,1))\n",
    "    return matrix.shape[0], matrix\n",
    "\n",
    "def generate_reaction_network_from_matrix(interaction_matrix: np.ndarray):\n",
    "    n_genes = interaction_matrix.shape[0]\n",
    "    gene_list = [f\"gene_{i+1}\" for i in range(n_genes)]\n",
    "    prop = {\n",
    "        \"regulatory\": \"(({sign}*{p_add})*({activator}_protein**{n})/({k}**{n}+{activator}_protein**{n}))*{target}_I\",\n",
    "        \"activation\": \"{p_on}*{target}_I\",\n",
    "        \"inactivation\": \"{p_off}*{target}_A\",\n",
    "        \"mRNA_prod\": \"{p_prod_mRNA}*{target}_A\",\n",
    "        \"mRNA_deg\": \"{p_deg_mRNA}*{target}_mRNA\",\n",
    "        \"protein_prod\": \"{p_prod_protein}*{target}_mRNA\",\n",
    "        \"protein_deg\": \"{p_deg_protein}*{target}_protein\"\n",
    "    }\n",
    "    reactions = []\n",
    "    for j, target in enumerate(gene_list):\n",
    "        param = lambda p: f\"{{{p}_{target}}}\"\n",
    "        # activation\n",
    "        expr = prop[\"activation\"].replace(\"{p_on}\", param(\"p_on\")).replace(\"{target}\", target)\n",
    "        reactions.append({\"species1\":f\"{target}_A\",\"change1\":1,\n",
    "                          \"species2\":f\"{target}_I\",\"change2\":-1,\n",
    "                          \"propensity\":expr,\"time\":\"-\"})\n",
    "        # regulation\n",
    "        regulators = np.where(interaction_matrix[:,j]!=0)[0]\n",
    "        for i in regulators:\n",
    "            source = gene_list[i]\n",
    "            sign = int(np.sign(interaction_matrix[i,j]))\n",
    "            edge = f\"{source}_to_{target}\"\n",
    "            expr = prop[\"regulatory\"]\\\n",
    "                .replace(\"{sign}\",str(sign))\\\n",
    "                .replace(\"{p_add}\",f\"{{p_add_{edge}}}\")\\\n",
    "                .replace(\"{n}\",f\"{{n_{edge}}}\")\\\n",
    "                .replace(\"{k}\",f\"{{k_{edge}}}\")\\\n",
    "                .replace(\"{activator}\",source)\\\n",
    "                .replace(\"{target}\",target)\n",
    "            reactions.append({\"species1\":f\"{target}_A\",\"change1\":1,\n",
    "                              \"species2\":f\"{target}_I\",\"change2\":-1,\n",
    "                              \"propensity\":expr,\"time\":\"-\"})\n",
    "        # inactivation\n",
    "        expr = prop[\"inactivation\"].replace(\"{p_off}\",param(\"p_off\")).replace(\"{target}\",target)\n",
    "        reactions.append({\"species1\":f\"{target}_I\",\"change1\":1,\n",
    "                          \"species2\":f\"{target}_A\",\"change2\":-1,\n",
    "                          \"propensity\":expr,\"time\":\"-\"})\n",
    "        # production/degradation\n",
    "        for label,suffix,chg in [\n",
    "            (\"mRNA_prod\",\"mRNA\",1),(\"mRNA_deg\",\"mRNA\",-1),\n",
    "            (\"protein_prod\",\"protein\",1),(\"protein_deg\",\"protein\",-1)\n",
    "        ]:\n",
    "            expr = prop[label].replace(\"{target}\",target)\n",
    "            for p in [\"p_prod_mRNA\",\"p_deg_mRNA\",\"p_prod_protein\",\"p_deg_protein\"]:\n",
    "                expr = expr.replace(f\"{{{p}}}\",param(p))\n",
    "            reactions.append({\"species1\":f\"{target}_{suffix}\",\"change1\":chg,\n",
    "                              \"species2\":\"-\",\"change2\":\"-\",\n",
    "                              \"propensity\":expr,\"time\":\"-\"})\n",
    "    df = pd.DataFrame(reactions)\n",
    "    df['propensity'] = df['propensity'].astype(str)\n",
    "    reactions_df = (\n",
    "        df.groupby(['species1','change1','species2','change2','time'])['propensity']\n",
    "          .agg(lambda x: ' + '.join(x)).reset_index()\n",
    "    )\n",
    "    return reactions_df, gene_list\n",
    "\n",
    "def generate_initial_state_from_genes(gene_list):\n",
    "    states = []\n",
    "    for g in gene_list:\n",
    "        states += [\n",
    "            {\"species\":f\"{g}_A\",\"count\":0},\n",
    "            {\"species\":f\"{g}_I\",\"count\":1},\n",
    "            {\"species\":f\"{g}_mRNA\",\"count\":0},\n",
    "            {\"species\":f\"{g}_protein\",\"count\":0},\n",
    "        ]\n",
    "    return pd.DataFrame(states)\n",
    "\n",
    "def assign_parameters_to_genes(csv_path, gene_list, rows=None):\n",
    "    df = pd.read_csv(csv_path, index_col=0)\n",
    "    n = len(gene_list)\n",
    "    if rows is None:\n",
    "        rows = np.random.choice(df.index, size=n, replace=True)\n",
    "    param_dict = {}\n",
    "    param_matrix = {}\n",
    "    for i,row in enumerate(rows):\n",
    "        gene = gene_list[i]\n",
    "        vals = df.loc[row].copy()\n",
    "        vals[\"p_deg_mRNA\"] = np.log(2)/vals[\"mrna_half_life\"]\n",
    "        vals[\"p_deg_protein\"] = np.log(2)/vals[\"protein_half_life\"]\n",
    "        vals.drop([\"mrna_half_life\",\"protein_half_life\"],axis=0,inplace=True,errors=\"ignore\")\n",
    "        param_matrix[gene] = vals\n",
    "        for k,v in vals.items():\n",
    "            param_dict[f\"{{{k}_{gene}}}\"] = float(v)\n",
    "    return param_dict, pd.DataFrame(param_matrix).T\n",
    "\n",
    "def generate_k_from_steady_state_calc(param_dict, interaction_matrix, gene_list,\n",
    "                                      target_hill=0.5, scale_k=None):\n",
    "    n_genes = len(gene_list)\n",
    "    if scale_k is None:\n",
    "        scale_k = np.ones((n_genes, n_genes))\n",
    "    protein_levels = np.zeros(n_genes)\n",
    "    for i,gene in enumerate(gene_list):\n",
    "        p_on = param_dict[f'{{p_on_{gene}}}']\n",
    "        p_off = param_dict[f'{{p_off_{gene}}}']\n",
    "        p_prod_mRNA = param_dict[f'{{p_prod_mRNA_{gene}}}']\n",
    "        p_deg_mRNA  = param_dict[f'{{p_deg_mRNA_{gene}}}']\n",
    "        p_prod_prot = param_dict[f'{{p_prod_protein_{gene}}}']\n",
    "        p_deg_prot  = param_dict[f'{{p_deg_protein_{gene}}}']\n",
    "        reg_eff = 0.0\n",
    "        regs = np.where(interaction_matrix[:,i]!=0)[0]\n",
    "        for r in regs:\n",
    "            edge = f\"{gene_list[r]}_to_{gene}\"\n",
    "            p_add = param_dict.get(f\"{{p_add_{edge}}}\", 0.0)\n",
    "            sign = interaction_matrix[r,i]\n",
    "            reg_eff += target_hill * p_add * sign\n",
    "        p_on_eff = p_on + reg_eff\n",
    "        burst_prob = p_on_eff/(p_on_eff+p_off)\n",
    "        m = p_prod_mRNA * burst_prob / p_deg_mRNA\n",
    "        protein_levels[i] = max(m * p_prod_prot / p_deg_prot, 0.1)\n",
    "    # assign k values\n",
    "    for i,src in enumerate(gene_list):\n",
    "        for j,tgt in enumerate(gene_list):\n",
    "            if interaction_matrix[i,j]!=0:\n",
    "                key = f\"{{k_{src}_to_{tgt}}}\"\n",
    "                param_dict[key] = protein_levels[i]*scale_k[i,j]\n",
    "    return protein_levels, param_dict\n",
    "\n",
    "def add_interaction_terms(param_dict, interaction_matrix, gene_list,\n",
    "                          n_matrix=None, p_add_matrix=None):\n",
    "    n = len(gene_list)\n",
    "    if n_matrix is None:\n",
    "        n_matrix = np.full((n,n),2.0)\n",
    "    if p_add_matrix is None:\n",
    "        p_add_matrix = np.full((n,n),10.0)\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if interaction_matrix[i,j]!=0:\n",
    "                edge = f\"{gene_list[i]}_to_{gene_list[j]}\"\n",
    "                param_dict[f\"{{n_{edge}}}\"]     = float(n_matrix[i,j])\n",
    "                param_dict[f\"{{p_add_{edge}}}\"] = float(p_add_matrix[i,j])\n",
    "    return generate_k_from_steady_state_calc(param_dict, interaction_matrix, gene_list)\n",
    "\n",
    "def setup_gillespie_params_from_reactions(init_states: pd.DataFrame,\n",
    "                                          reactions: pd.DataFrame,\n",
    "                                          param_dictionary: dict):\n",
    "    species_index = {s:i for i,s in enumerate(init_states['species'])}\n",
    "    pop0 = init_states['count'].values.astype(np.int64)\n",
    "    update_matrix = []\n",
    "    prop_formulas = []\n",
    "    missing = []\n",
    "    for i,row in reactions.iterrows():\n",
    "        delta = [0]*len(species_index)\n",
    "        a1,a2 = row['species1'], row['species2']\n",
    "        delta[species_index[a1]] = int(row['change1'])\n",
    "        if a2!='-':\n",
    "            delta[species_index[a2]] = int(row['change2'])\n",
    "        update_matrix.append(delta)\n",
    "        expr = row['propensity']\n",
    "        # inject species\n",
    "        for s,idx in species_index.items():\n",
    "            expr = expr.replace(s, f\"pop[idx_{s}]\")\n",
    "        # inject params\n",
    "        placeholders = set(re.findall(r\"{[^}]+}\", expr))\n",
    "        miss = placeholders - set(param_dictionary.keys())\n",
    "        if miss:\n",
    "            missing.append((i, miss))\n",
    "            continue\n",
    "        for k,v in param_dictionary.items():\n",
    "            expr = expr.replace(k, str(v))\n",
    "        line = f\"prop[{i}] = {expr}\"\n",
    "        prop_formulas.append(line)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing params in propensities: {missing}\")\n",
    "    # build update function\n",
    "    src = [\"@numba.njit(fastmath=True)\",\n",
    "           \"def update_propensities(prop, pop, t):\"]\n",
    "    for s,i in species_index.items():\n",
    "        src.append(f\"    idx_{s} = {i}\")\n",
    "    for L in prop_formulas:\n",
    "        src.append(\"    \" + L)\n",
    "    ns = \"\\n\".join(src)\n",
    "    loc = {}\n",
    "    exec(ns, {'numba':numba}, loc)\n",
    "    return pop0, np.array(update_matrix, dtype=np.int64), loc['update_propensities'], species_index\n",
    "\n",
    "# %% SSA core JIT\n",
    "\n",
    "@numba.njit(fastmath=True)\n",
    "def sample_discrete(probs):\n",
    "    q = np.random.rand()\n",
    "    cum = 0.0\n",
    "    for i in range(probs.shape[0]):\n",
    "        cum += probs[i]\n",
    "        if cum >= q:\n",
    "            return i\n",
    "    return probs.shape[0]-1\n",
    "\n",
    "@numba.njit(fastmath=True)\n",
    "def gillespie_draw(prop_func, prop, pop, t):\n",
    "    prop_func(prop, pop, t)\n",
    "    total = prop.sum()\n",
    "    if total <= 0:\n",
    "        return -1, -1.0\n",
    "    dt = np.random.exponential(1.0 / total)\n",
    "    q = np.random.rand()\n",
    "    cum = 0.0\n",
    "    for i in range(prop.shape[0]):\n",
    "        cum += prop[i] / total\n",
    "        if cum >= q:\n",
    "            return i, dt\n",
    "    return prop.shape[0] - 1, dt\n",
    "\n",
    "# %% Vectorized extraction\n",
    "\n",
    "def extract_mrna_protein_fast(samples: np.ndarray, species_index: dict,\n",
    "                              types=('mRNA','protein')) -> pd.DataFrame:\n",
    "    n_cells, n_time, _ = samples.shape\n",
    "    sel = [(name,idx) for name,idx in species_index.items()\n",
    "           if any(name.endswith(t) for t in types)]\n",
    "    names, idxs = zip(*sel)\n",
    "    data = samples[:,:,idxs].reshape(n_cells*n_time, len(idxs))\n",
    "    cell_ids   = np.repeat(np.arange(n_cells), n_time)\n",
    "    time_steps = np.tile(np.arange(n_time), n_cells)\n",
    "    df = pd.DataFrame(data, columns=names)\n",
    "    df.insert(0,'time_step',time_steps)\n",
    "    df.insert(0,'cell_id',cell_ids)\n",
    "    return df\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Main\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting simulation...\n",
      "20 threads: 3364.3331327904016\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import uuid\n",
    "import json\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numba\n",
    "from numba import prange\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import numba\n",
    "from numba import prange\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import numba\n",
    "from numba import prange\n",
    "from tqdm import tqdm\n",
    "\n",
    "@numba.njit(fastmath=True)\n",
    "def gillespie_draw(prop_func, prop, pop, t):\n",
    "    prop_func(prop, pop, t)\n",
    "    total = 0.0\n",
    "    for r in range(prop.shape[0]):\n",
    "        total += prop[r]\n",
    "    if total <= 0:\n",
    "        return -1, -1.0\n",
    "    dt = np.random.exponential(1.0 / total)\n",
    "    q = np.random.rand()\n",
    "    cum = 0.0\n",
    "    for r in range(prop.shape[0]):\n",
    "        cum += prop[r] / total\n",
    "        if cum >= q:\n",
    "            return r, dt\n",
    "    return prop.shape[0] - 1, dt\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=True)\n",
    "def simulate_cells_numba(update_propensities, update_matrix, pop0_mat, time_points, verbose_flags):\n",
    "    n_species, n_cells = pop0_mat.shape\n",
    "    n_time = time_points.shape[0]\n",
    "    n_rxns = update_matrix.shape[0]\n",
    "    samples = np.zeros((n_cells, n_time, n_species), dtype=np.int64)\n",
    "\n",
    "    for cell in prange(n_cells):\n",
    "        pop = pop0_mat[:, cell].copy()\n",
    "        prev = pop.copy()\n",
    "        t = time_points[0]\n",
    "        samples[cell, 0, :] = pop\n",
    "        i_time = 1\n",
    "        stuck_counter = 0\n",
    "        max_attempts = 10000\n",
    "        prop = np.zeros(n_rxns, dtype=np.float64)\n",
    "\n",
    "        while i_time < n_time:\n",
    "            update_propensities(prop, pop, t)\n",
    "            total = prop.sum()\n",
    "            if total <= 0:\n",
    "                stuck_counter += 1\n",
    "                if stuck_counter > max_attempts:\n",
    "                    verbose_flags[cell] = 1\n",
    "                    break\n",
    "                continue\n",
    "            stuck_counter = 0\n",
    "            dt = np.random.exponential(1.0 / total)\n",
    "            q = np.random.rand()\n",
    "            cum = 0.0\n",
    "            for i in range(n_rxns):\n",
    "                cum += prop[i] / total\n",
    "                if cum >= q:\n",
    "                    rxn = i\n",
    "                    break\n",
    "            else:\n",
    "                rxn = n_rxns - 1\n",
    "\n",
    "            prev = pop.copy()\n",
    "            for s in range(n_species):\n",
    "                pop[s] += update_matrix[rxn, s]\n",
    "            t += dt\n",
    "\n",
    "            # Fill all skipped time points\n",
    "            while i_time < n_time and t >= time_points[i_time]:\n",
    "                samples[cell, i_time, :] = prev\n",
    "                i_time += 1\n",
    "\n",
    "    return samples\n",
    "\n",
    "\n",
    "def run_simulation(update_propensities, update_matrix, pop0, time_points, n_cells=10):\n",
    "    n_species = pop0.shape[0]\n",
    "    pop0_mat = np.tile(pop0[:, None], (1, n_cells))\n",
    "    verbose_flags = np.zeros(n_cells, dtype=np.int64)\n",
    "\n",
    "    # Warm-up call to compile JIT\n",
    "    # _ = simulate_cells_numba(update_propensities, update_matrix, pop0_mat[:, :1], time_points, np.zeros(1, dtype=np.int64))\n",
    "\n",
    "    # Actual run\n",
    "    print(\"Starting simulation...\")\n",
    "    samples = simulate_cells_numba(update_propensities, update_matrix, pop0_mat, time_points, verbose_flags)\n",
    "\n",
    "    for cell in range(n_cells):\n",
    "        if verbose_flags[cell] == 1:\n",
    "            print(f\"⚠️  WARNING: Cell {cell} got stuck (zero propensities too long).\")\n",
    "        elif verbose_flags[cell] == 2:\n",
    "            print(f\"⚠️  WARNING: Cell {cell} exceeded max allowed events.\")\n",
    "\n",
    "    return samples\n",
    "\n",
    "# Example usage:\n",
    "# Define time_points, pop0, update_matrix, update_propensities\n",
    "# samples = run_simulation(update_propensities, update_matrix, pop0, time_points)\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# Define time_points, pop0, update_matrix, update_propensities as needed\n",
    "# samples = run_simulation(update_propensities, update_matrix, pop0, time_points)\n",
    "\n",
    "# … [vectorized extraction function] …\n",
    "import time\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # === user parameters ===\n",
    "    path_to_matrix =  \"/home/mzo5929/Keerthana/grnInference/simulation_data/general_simulation_data/test_data/matrix101.txt\"\n",
    "    param_csv      = \"/home/mzo5929/Keerthana/grnInference/simulation_data/general_simulation_data/test_data/parameter_sheet_gillespie.csv\"\n",
    "    rows           = [14,14]\n",
    "    p_add_matrix   = np.array([[0.0,2.0],[0,0]])\n",
    "    n_matrix       = np.array([[0.0,4.41],[0,0]])\n",
    "    n_cells        = 100\n",
    "    time_duration  = 1000\n",
    "    time_points    = np.arange(0, time_duration, 1)\n",
    "\n",
    "    # read & build\n",
    "    n_genes, mat = read_input_matrix(path_to_matrix)\n",
    "    reactions_df, gene_list = generate_reaction_network_from_matrix(mat)\n",
    "    init_states = generate_initial_state_from_genes(gene_list)\n",
    "    param_dict, _ = assign_parameters_to_genes(param_csv, gene_list, rows)\n",
    "    steady_state, full_param_dict = add_interaction_terms(\n",
    "        param_dict, mat, gene_list,\n",
    "        n_matrix=n_matrix,\n",
    "        p_add_matrix=p_add_matrix\n",
    "    )\n",
    "    pop0, update_matrix, update_prop, species_index = setup_gillespie_params_from_reactions(\n",
    "        init_states, reactions_df, full_param_dict\n",
    "    )\n",
    "    # build pop0_mat and allocate final array\n",
    "    pop0_mat = np.tile(pop0[:,None], (1,n_cells))\n",
    "    # samples = np.zeros((n_cells, len(time_points), pop0_mat.shape[0]), dtype=np.int64)\n",
    "    import os\n",
    "    # print(\"Starting test\")\n",
    "    # os.environ[\"NUMBA_NUM_THREADS\"] = \"1\"\n",
    "    # # # warm-up...\n",
    "    # t1 = time.perf_counter()\n",
    "    # samples = run_simulation(update_prop, update_matrix, pop0, time_points)\n",
    "    # print(\"1 thread:\", time.perf_counter()-t1)\n",
    "\n",
    "    # from numba import set_num_threads, get_num_threads\n",
    "    # os.environ[\"NUMBA_NUM_THREADS\"] = \"8\"\n",
    "    # warm-up again if needed...\n",
    "    t8 = time.perf_counter()\n",
    "    samples = run_simulation(update_prop, update_matrix, pop0, time_points,n_cells=n_cells)\n",
    "    print(\"20 threads:\", time.perf_counter()-t8)\n",
    "\n",
    "    # extract & save\n",
    "    df = extract_mrna_protein_fast(samples, species_index)\n",
    "    prefix = f\"{n_cells}_cells_{time_duration}h_{uuid.uuid4().hex[:8]}\"\n",
    "    df.to_csv(f\"test_df_14_14_{prefix}.csv\", index=False)\n",
    "    np.savetxt(f\"test_samples_14_14_{prefix}.csv\", samples.reshape(n_cells,-1), delimiter=\",\")\n",
    "    record = {\n",
    "        \"id\": prefix,\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"param_dict\": param_dict,\n",
    "        \"steady_state\": steady_state.tolist(),\n",
    "    }\n",
    "    with open(\"simulation_metadata.jsonl\",\"a\") as f:\n",
    "        f.write(json.dumps(record)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1000_cells_1000h_af596bb8'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grnSimulationQuest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

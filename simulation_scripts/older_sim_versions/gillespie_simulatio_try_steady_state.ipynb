{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for Gillespie simulations\n",
    "\n",
    "## Steps\n",
    "\n",
    "- Input\n",
    "  - Read the input matrix\n",
    "  - create reactions\n",
    "  - the update matrices\n",
    "- Generate the steady state distribution\n",
    "  - Every 300 time steps, give birth to a cell\n",
    "  - simulate the cells in parallel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import re\n",
    "import numba\n",
    "from numba import njit\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "from tqdm.auto import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the matrix\n",
    "def read_input_matrix(path_to_matrix):\n",
    "    \"\"\"\n",
    "    Reads the input matrix from the specified file path and counts number of genes.\n",
    "    \n",
    "    Parameters:\n",
    "    path_to_matrix (str): The file path to the input matrix.\n",
    "    \n",
    "    Returns:\n",
    "    np.ndarray: The input matrix as a NumPy array.\n",
    "    \"\"\"\n",
    "    matrix = np.loadtxt(path_to_matrix, dtype='i', delimiter=',')\n",
    "    if matrix.ndim == 0:\n",
    "        matrix = np.array([[matrix]])\n",
    "\n",
    "    # print(type(matrix))\n",
    "    # print(matrix.shape)\n",
    "    return matrix.shape[0], matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_reaction_network_from_matrix(interaction_matrix):\n",
    "    \"\"\"\n",
    "    Generate a reaction DataFrame directly from a signed interaction matrix.\n",
    "    Assumes gene-specific parameters and interaction-specific regulation.\n",
    "\n",
    "    Args:\n",
    "        interaction_matrix (np.ndarray): shape (n_genes, n_genes)\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: reactions\n",
    "        List[str]: gene names\n",
    "    \"\"\"\n",
    "    n_genes = interaction_matrix.shape[0]\n",
    "    gene_list = [f\"gene_{i+1}\" for i in range(n_genes)]\n",
    "\n",
    "    prop = {\n",
    "        \"regulatory\": \"(({sign}*{p_add})*({activator}_protein**{n})/({k}**{n} + {activator}_protein**{n}))*{target}_I\",\n",
    "        \"activation\": \"{p_on}*{target}_I\",\n",
    "        \"inactivation\": \"{p_off}*{target}_A\",\n",
    "        \"mRNA_prod\": \"{p_prod_mRNA}*{target}_A\",\n",
    "        \"mRNA_deg\": \"{p_deg_mRNA}*{target}_mRNA\",\n",
    "        \"protein_prod\": \"{p_prod_protein}*{target}_mRNA\",\n",
    "        \"protein_deg\": \"{p_deg_protein}*{target}_protein\"\n",
    "    }\n",
    "\n",
    "    reactions = []\n",
    "\n",
    "    for j, target_gene in enumerate(gene_list):\n",
    "        param = lambda p: f\"{{{p}_{target_gene}}}\"\n",
    "\n",
    "        # Activation (gene_I → gene_A)\n",
    "        expr = prop[\"activation\"]\n",
    "        expr = expr.replace(\"{p_on}\", param(\"p_on\")).replace(\"{target}\", target_gene)\n",
    "        reactions.append({\n",
    "            \"species1\": f\"{target_gene}_A\", \"change1\": 1,\n",
    "            \"species2\": f\"{target_gene}_I\", \"change2\": -1,\n",
    "            \"propensity\": expr, \"time\": \"-\"\n",
    "        })\n",
    "\n",
    "        # Regulation by other genes (column j)\n",
    "        regulators = np.where(interaction_matrix[:, j] != 0)[0]\n",
    "        for i in regulators:\n",
    "            source_gene = gene_list[i]\n",
    "            sign = int(np.sign(interaction_matrix[i, j]))\n",
    "            edge_tag = f\"{source_gene}_to_{target_gene}\"\n",
    "\n",
    "            expr = prop[\"regulatory\"]\n",
    "            expr = expr.replace(\"{sign}\", str(sign))\n",
    "            expr = expr.replace(\"{p_add}\", f\"{{p_add_{edge_tag}}}\")\n",
    "            expr = expr.replace(\"{n}\", f\"{{n_{edge_tag}}}\")\n",
    "            expr = expr.replace(\"{k}\", f\"{{k_{edge_tag}}}\")\n",
    "            expr = expr.replace(\"{activator}\", source_gene)\n",
    "            expr = expr.replace(\"{target}\", target_gene)\n",
    "\n",
    "            reactions.append({\n",
    "                \"species1\": f\"{target_gene}_A\", \"change1\": 1,\n",
    "                \"species2\": f\"{target_gene}_I\", \"change2\": -1,\n",
    "                \"propensity\": expr, \"time\": \"-\"\n",
    "            })\n",
    "\n",
    "        # Inactivation (gene_A → gene_I)\n",
    "        expr = prop[\"inactivation\"]\n",
    "        expr = expr.replace(\"{p_off}\", param(\"p_off\")).replace(\"{target}\", target_gene)\n",
    "        reactions.append({\n",
    "            \"species1\": f\"{target_gene}_I\", \"change1\": 1,\n",
    "            \"species2\": f\"{target_gene}_A\", \"change2\": -1,\n",
    "            \"propensity\": expr, \"time\": \"-\"\n",
    "        })\n",
    "\n",
    "        # Transcription & translation (uses gene-specific params)\n",
    "        for label, suffix, change in [\n",
    "            (\"mRNA_prod\", \"mRNA\", 1),\n",
    "            (\"mRNA_deg\", \"mRNA\", -1),\n",
    "            (\"protein_prod\", \"protein\", 1),\n",
    "            (\"protein_deg\", \"protein\", -1)\n",
    "        ]:\n",
    "            expr = prop[label].replace(\"{target}\", target_gene)\n",
    "            for p in [\"d\", \"p_prod_mRNA\", \"p_deg_mRNA\", \"p_prod_protein\", \"p_deg_protein\"]:\n",
    "                expr = expr.replace(f\"{{{p}}}\", param(p))\n",
    "            reactions.append({\n",
    "                \"species1\": f\"{target_gene}_{suffix}\", \"change1\": change,\n",
    "                \"species2\": \"-\", \"change2\": \"-\",\n",
    "                \"propensity\": expr, \"time\": \"-\"\n",
    "            })\n",
    "\n",
    "    # Consolidate reactions with same species1/species2/change values\n",
    "    df = pd.DataFrame(reactions)\n",
    "    df['propensity'] = df['propensity'].astype(str)\n",
    "    reactions_df = (\n",
    "        df.groupby(['species1', 'change1', 'species2', 'change2', 'time'])['propensity']\n",
    "          .agg(lambda x: ' + '.join(x))\n",
    "          .reset_index()\n",
    "    )\n",
    "    return reactions_df, gene_list\n",
    "\n",
    "def generate_initial_state_from_genes(gene_list):\n",
    "    \"\"\"\n",
    "    Generate an initial state where all genes are inactive and have zero mRNA/protein.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame with columns ['species', 'count']\n",
    "    \"\"\"\n",
    "    states = []\n",
    "    for gene in gene_list:\n",
    "        states.extend([\n",
    "            {\"species\": f\"{gene}_A\", \"count\": 0},\n",
    "            {\"species\": f\"{gene}_I\", \"count\": 1},\n",
    "            {\"species\": f\"{gene}_mRNA\", \"count\": 0},\n",
    "            {\"species\": f\"{gene}_protein\", \"count\": 0}\n",
    "        ])\n",
    "    return pd.DataFrame(states)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_parameters_to_genes(csv_path, n_genes, rows=None):\n",
    "    \"\"\"\n",
    "    Assigns parameters from CSV to genes and returns a param_dict for expression substitution.\n",
    "    \n",
    "    Args:\n",
    "        csv_path (str): Path to parameter CSV file\n",
    "        rows (list of int, optional): Specific row indices to select. If None, selects randomly.\n",
    "        n_random (int): Number of random rows to select if rows is None.\n",
    "    \n",
    "    Returns:\n",
    "        tuple:\n",
    "            param_dict (dict): {\"{param_geneX}\": value}\n",
    "            param_matrix (pd.DataFrame): gene-wise parameter values\n",
    "            row_mapping (dict): {\"gene_X\": row_index}\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path, index_col=0)\n",
    "\n",
    "    # Select rows to assign to genes\n",
    "    if rows is None:\n",
    "        rows = np.random.choice(df.index, size=n_genes, replace=True)\n",
    "\n",
    "    param_dict = {}\n",
    "    param_matrix = {}\n",
    "    row_mapping = {}\n",
    "\n",
    "    for i, row in enumerate(rows):\n",
    "        gene = f\"gene_{i+1}\"\n",
    "        values = df.loc[row].copy()\n",
    "        row_mapping[gene] = row\n",
    "\n",
    "        # Derived params\n",
    "        values[\"p_deg_mRNA\"] = np.log(2) / values[\"mrna_half_life\"]\n",
    "        values[\"p_deg_protein\"] = np.log(2) / values[\"protein_half_life\"]\n",
    "\n",
    "        # Remove unused columns\n",
    "        values.drop([\"mrna_half_life\", \"protein_half_life\", \"burst_size\"], inplace=True, errors=\"ignore\")\n",
    "\n",
    "        # Add to param_matrix\n",
    "        param_matrix[gene] = values\n",
    "\n",
    "        # Flatten into param_dict with curly-brace keys\n",
    "        for param, val in values.items():\n",
    "            param_dict[f\"{{{param}_{gene}}}\"] = val\n",
    "\n",
    "    param_matrix_df = pd.DataFrame(param_matrix).T\n",
    "    return param_dict, param_matrix_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An useful utility function that is not used for simulation\n",
    "# def calculate_unregulated_protein_levels(p_on, p_off, p_prod_mRNA, p_deg_mRNA, p_prod_protein, p_deg_protein, global_params=None):\n",
    "#     \"\"\"\n",
    "#     Calculate protein levels without any regulation (for comparison/initialization).\n",
    "    \n",
    "#     Args:\n",
    "#         param_matrix (pd.DataFrame): Gene parameters\n",
    "#         global_params (dict, optional): Global constants\n",
    "        \n",
    "#     Returns:\n",
    "#         np.ndarray: Unregulated steady-state protein levels\n",
    "#     \"\"\"    \n",
    "#     # Calculate unregulated levels\n",
    "#     burst_prob = p_on / (p_on + p_off)\n",
    "#     mRNA = p_prod_mRNA * burst_prob / (p_deg_mRNA)\n",
    "#     protein_levels = mRNA * p_prod_protein / p_deg_protein\n",
    "    # return protein_levels\n",
    "\n",
    "def generate_k_from_steady_state_calc(param_dict, interaction_matrix, gene_list,\n",
    "                                        global_params=None, target_hill=0.5, scale_k=None, verbose=False):\n",
    "    \"\"\"\n",
    "    Calculate steady-state protein levels using regulated k_on_eff for each gene,\n",
    "    and update EC50 (k_*) values only for actual regulatory edges.\n",
    "\n",
    "    Args:\n",
    "        param_dict (dict): Parameter dictionary with gene-specific and edge-specific entries.\n",
    "        interaction_matrix (np.ndarray): shape (n_genes, n_genes), effect of gene i on gene j.\n",
    "        gene_list (list): List of gene names in order.\n",
    "        global_params (dict): Optional global constants (unused).\n",
    "        target_hill (float): Hill output to match when computing EC50.\n",
    "        scale_k (np.ndarray or None): shape (n_genes, n_genes). scale_k[i, j] applies to k_{i→j}.\n",
    "                                      Defaults to 1.0 for all entries.\n",
    "        verbose (bool): Print debug info.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (np.ndarray of steady-state protein levels, updated param_dict with k_* entries)\n",
    "    \"\"\"\n",
    "    n_genes = len(gene_list)\n",
    "\n",
    "    if scale_k is None:\n",
    "        scale_k = np.ones((n_genes, n_genes))\n",
    "    else:\n",
    "        scale_k = np.asarray(scale_k)\n",
    "        assert scale_k.shape == (n_genes, n_genes), \"scale_k must be of shape (n_genes, n_genes)\"\n",
    "\n",
    "    protein_levels = np.zeros(n_genes)\n",
    "    p_on_eff = np.zeros(n_genes)\n",
    "\n",
    "    for i in range(n_genes):\n",
    "        gene = gene_list[i]\n",
    "        p_on = param_dict[f'{{p_on_{gene}}}']\n",
    "        p_off = param_dict[f'{{p_off_{gene}}}']\n",
    "        p_prod_mRNA = param_dict[f'{{p_prod_mRNA_{gene}}}']\n",
    "        p_deg_mRNA = param_dict[f'{{p_deg_mRNA_{gene}}}']\n",
    "        p_prod_protein = param_dict[f'{{p_prod_protein_{gene}}}']\n",
    "        p_deg_protein = param_dict[f'{{p_deg_protein_{gene}}}']\n",
    "\n",
    "\n",
    "        # Sum regulatory contributions\n",
    "        regulatory_effect = 0.0\n",
    "        regulators = np.where(interaction_matrix[:, i] != 0)[0]\n",
    "\n",
    "        for reg in regulators:\n",
    "            source = gene_list[reg]\n",
    "            edge = f\"{source}_to_{gene}\"\n",
    "            print(param_dict)\n",
    "            p_add = param_dict.get(f\"{{p_add_{edge}}}\", 0)\n",
    "            sign = interaction_matrix[reg, i]\n",
    "            regulatory_effect += target_hill * p_add * sign\n",
    "            print(source, edge, p_add, sign, regulatory_effect)\n",
    "\n",
    "        p_on_eff[i] = p_on + regulatory_effect\n",
    "\n",
    "        # # Compute protein level using k_on_eff\n",
    "        burst_prob = p_on_eff[i] / (p_on_eff[i] + p_off)\n",
    "        mRNA = p_prod_mRNA * burst_prob / p_deg_mRNA\n",
    "        protein = mRNA * p_prod_protein / p_deg_protein\n",
    "\n",
    "        protein_levels[i] = max(protein, 0.1)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Gene {gene}: k_on = {k_on:.3f} → k_on_eff = {k_on_eff[i]:.3f} \"\n",
    "                  f\"(reg_effect: {regulatory_effect:.3f}) → Protein level: {protein_levels[i]:.3f}\")\n",
    "\n",
    "        # Assign EC50 values (k_*) only for actual edges, scaled with scale_k[i, j]\n",
    "    for i in range(n_genes):\n",
    "        source_gene = gene_list[i]\n",
    "        targets = np.where(interaction_matrix[i, :] != 0)[0]\n",
    "        for j in targets:\n",
    "            target_gene = gene_list[j]\n",
    "            key = f\"{{k_{source_gene}_to_{target_gene}}}\"\n",
    "            param_dict[key] = protein_levels[i] * scale_k[i, j]\n",
    "\n",
    "    return protein_levels, param_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_interaction_terms(param_dict, interaction_matrix, gene_list, n_matrix=None, p_add_matrix=None):\n",
    "    \"\"\"\n",
    "    Add n and p_add terms to param_dict based on interaction_matrix.\n",
    "    Also calculates EC50 (k) values using steady-state protein levels.\n",
    "\n",
    "    Args:\n",
    "        param_dict (dict): Initial dictionary of gene-specific parameters.\n",
    "        interaction_matrix (np.ndarray): Regulatory interactions (2D array).\n",
    "        gene_list (list): List of gene names like ['gene_1', 'gene_2', ...].\n",
    "        n_matrix (np.ndarray, optional): Matrix of Hill coefficients (defaults to 2).\n",
    "        p_add_matrix (np.ndarray, optional): Matrix of r_add values (defaults to 10).\n",
    "\n",
    "    Returns:\n",
    "        dict: Updated param_dict including n, p_add, and k values.\n",
    "    \"\"\"\n",
    "    interaction_matrix = np.array(interaction_matrix)\n",
    "    n_genes = len(gene_list)\n",
    "    param_dict_updated = param_dict.copy()\n",
    "    if n_matrix is None:\n",
    "        n_matrix = np.full((n_genes, n_genes), 2)\n",
    "    if p_add_matrix is None:\n",
    "        p_add_matrix = np.full((n_genes, n_genes), 10)\n",
    "\n",
    "    for i in range(n_genes):\n",
    "        for j in range(n_genes):\n",
    "            if interaction_matrix[i, j] != 0:\n",
    "                gene_i = gene_list[i]\n",
    "                gene_j = gene_list[j]\n",
    "                edge = f\"{gene_i}_to_{gene_j}\"\n",
    "\n",
    "                param_dict_updated[f\"{{n_{edge}}}\"] = n_matrix[i, j]\n",
    "                param_dict_updated[f\"{{p_add_{edge}}}\"] = p_add_matrix[i, j]\n",
    "    # Generate EC50 values using the correct steady-state calculation\n",
    "    protein_levels, k_dict = generate_k_from_steady_state_calc(param_dict_updated, interaction_matrix, gene_list)\n",
    "\n",
    "    return protein_levels, k_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_gillespie_params_from_reactions(init_states, reactions, param_dictionary):\n",
    "    \"\"\"\n",
    "    Setup Gillespie update matrix and function using species and parameter templates.\n",
    "\n",
    "    Args:\n",
    "        init_states (pd.DataFrame): columns ['species', 'count']\n",
    "        reactions (pd.DataFrame): columns ['species1', 'change1', 'species2', 'change2', 'propensity', 'time']\n",
    "        param_dictionary (dict): Dictionary containing all parameters (e.g., p_on_*, k_*, p_add_*, ...)\n",
    "\n",
    "    Returns:\n",
    "        population_init (np.ndarray), update_matrix (np.ndarray), update_function (str), species_index (dict)\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If any required placeholder in reaction propensities is not in param_dictionary.\n",
    "    \"\"\"\n",
    "    init_states = init_states.dropna()\n",
    "    reactions = reactions.dropna()\n",
    "\n",
    "    species_index = {s: i for i, s in enumerate(init_states['species'])}\n",
    "    population_init = init_states['count'].values.astype(np.int64)\n",
    "    \n",
    "    update_matrix = []\n",
    "    propensity_formulas = []\n",
    "    missing_keys_report = []\n",
    "\n",
    "    for i, row in reactions.iterrows():\n",
    "        delta = [0] * len(species_index)\n",
    "        delta[species_index[row['species1']]] = int(row['change1'])\n",
    "        if row['species2'] != '-':\n",
    "            delta[species_index[row['species2']]] = int(row['change2'])\n",
    "        update_matrix.append(delta)\n",
    "\n",
    "        expr = row['propensity']\n",
    "\n",
    "        # Replace species with indexed population\n",
    "        for species, idx in species_index.items():\n",
    "            expr = expr.replace(species, f\"population[{idx}]\")\n",
    "\n",
    "        # Validate and inject all parameter placeholders\n",
    "        placeholders = set(re.findall(r\"{[^}]+}\", expr))\n",
    "        missing = placeholders - set(param_dictionary.keys())\n",
    "        if missing:\n",
    "            missing_keys_report.append((i, row['propensity'], list(missing)))\n",
    "            continue  # move to next reaction without injecting\n",
    "\n",
    "        for key, val in param_dictionary.items():\n",
    "            expr = expr.replace(key, str(val))\n",
    "\n",
    "        if row['time'] != '-':\n",
    "            line = f\"propensities[{i}] = ({expr}) if ({row['time']}) else 0\"\n",
    "        else:\n",
    "            line = f\"propensities[{i}] = {expr}\"\n",
    "        propensity_formulas.append(line)\n",
    "\n",
    "    if missing_keys_report:\n",
    "        error_message = \"Missing parameters in propensity expressions:\\n\"\n",
    "        for i, raw_expr, missing_keys in missing_keys_report:\n",
    "            error_message += f\"  [Reaction {i}] '{raw_expr}' is missing: {', '.join(missing_keys)}\\n\"\n",
    "        raise ValueError(error_message)\n",
    "\n",
    "    update_func = \"@numba.njit(fastmath=True)\\ndef update_propensities(propensities, population, t):\\n\\t\" + \"\\n\\t\".join(propensity_formulas)\n",
    "\n",
    "    return population_init, np.array(update_matrix, dtype=np.int64), update_func, species_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(fastmath = True)\n",
    "def sample_discrete(probs): #samples which reaction to run next\n",
    "    \"\"\"Randomly sample an index with probability given by probs.\"\"\"\n",
    "    # Generate random number\n",
    "    q = np.random.rand()\n",
    "\n",
    "    # Find index\n",
    "    i = 0\n",
    "    p_sum = 0.0\n",
    "    while p_sum < q:\n",
    "        p_sum += probs[i]\n",
    "        i += 1\n",
    "    return i - 1\n",
    "\n",
    "\n",
    "@njit(fastmath = True)\n",
    "def gillespie_draw(propensity_func, propensities, population, t):\n",
    "    \"\"\"\n",
    "    Draws a reaction and the time it took to do that reaction.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    propensity_func : function\n",
    "        Function with call signature propensity_func(population, t, *args)\n",
    "        used for computing propensities. This function must return\n",
    "        an array of propensities.\n",
    "    propensities : ndarray\n",
    "        Propensities for each reaction as a 1D Numpy array.\n",
    "    population : ndarray\n",
    "        Current population of particles (key entities of interest, ie TF(RNA), TF(P))\n",
    "    t : float\n",
    "        Value of the current time.\n",
    "    args : tuple, default ()\n",
    "        Arguments to be passed to `propensity_func`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    rxn : int\n",
    "        Index of reaction that occured.\n",
    "    time : float\n",
    "        Time it took for the reaction to occur.\n",
    "    \"\"\"\n",
    "    # Compute propensities\n",
    "    propensity_func(propensities, population, t)\n",
    "\n",
    "    # Sum of propensities\n",
    "    props_sum = propensities.sum()\n",
    "\n",
    "    # Compute next time\n",
    "    time = np.random.exponential(1.0 / props_sum) ## exponentially distributed state-switching\n",
    "\n",
    "    # Compute discrete probabilities of each reaction\n",
    "    rxn_probs = propensities / props_sum\n",
    "\n",
    "    # Draw reaction from this distribution\n",
    "    rxn = sample_discrete(rxn_probs) #sample_discrete(rxn_probs) or sample_discrete_scipy(rxn_probs)\n",
    "\n",
    "    return rxn, time\n",
    "\n",
    "def gillespie_ssa(propensity_func, update, population_0, time_points):\n",
    "    \"\"\"\n",
    "    Uses the Gillespie stochastic simulation algorithm to sample\n",
    "    from probability distribution of particle counts over time.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    propensity_func : function\n",
    "        Function of the form f(params, t, population) that takes the current\n",
    "        population of particle counts and returns an array of propensities\n",
    "        for each reaction.\n",
    "    update : ndarray, shape (num_reactions, num_chemical_species)\n",
    "        Entry i, j gives the change in particle counts of species j\n",
    "        for chemical reaction i.\n",
    "    population_0 : array_like, shape (num_chemical_species)\n",
    "        Array of initial populations of all chemical species.\n",
    "    time_points : array_like, shape (num_time_points,)\n",
    "        Array of points in time for which to sample the probability\n",
    "        distribution.\n",
    "    args : tuple, default ()\n",
    "        The set of parameters to be passed to propensity_func.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sample : ndarray, shape (num_time_points, num_chemical_species)\n",
    "        Entry i, j is the count of chemical species j at time\n",
    "        time_points[i].\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize output\n",
    "    pop_out = np.empty((len(time_points), update.shape[1]), dtype=np.int64)\n",
    "\n",
    "    # Initialize and perform simulation\n",
    "    i_time = 1\n",
    "    i = 0\n",
    "    t = time_points[0]\n",
    "    population = population_0.copy()\n",
    "    pop_out[0, :] = population\n",
    "    propensities = np.zeros(update.shape[0])\n",
    "    while i < len(time_points):\n",
    "        while t < time_points[i_time]:\n",
    "            # draw the event and time step\n",
    "            event, dt = gillespie_draw(propensity_func, propensities, population, t)\n",
    "\n",
    "            # Update the population\n",
    "            population_previous = population.copy()\n",
    "            population += update[event, :]\n",
    "\n",
    "            # Increment time\n",
    "            t += dt\n",
    "\n",
    "        # Update the index\n",
    "        # Replace inefficient comparison\n",
    "        i = np.searchsorted(time_points, t)\n",
    "\n",
    "\n",
    "        # Update the population\n",
    "        pop_out[i_time : min(i, len(time_points))] = population_previous\n",
    "\n",
    "        # Increment index\n",
    "        i_time = i\n",
    "\n",
    "    return pop_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mrna_protein(samples, species_index, types=('mRNA', 'protein')):\n",
    "    \"\"\"\n",
    "    Extract mRNA/protein data from a 3D samples array: (n_cells, n_timepoints, n_species)\n",
    "    \n",
    "    Args:\n",
    "        samples (np.ndarray): shape (n_cells, n_timepoints, n_species)\n",
    "        species_index (dict): species name → index\n",
    "        types (tuple): which species types to include\n",
    "    Returns:\n",
    "        pd.DataFrame\n",
    "    \"\"\"\n",
    "    n_cells, n_timepoints, _ = samples.shape\n",
    "    selected_species = {k: v for k, v in species_index.items() if any(k.endswith(t) for t in types)}\n",
    "    \n",
    "    records = []\n",
    "    for cell in range(n_cells):\n",
    "        for tp in range(n_timepoints):\n",
    "            row = {'cell_id': cell, 'time_step': tp}\n",
    "            for species, idx in selected_species.items():\n",
    "                row[species] = samples[cell, tp, idx]\n",
    "            records.append(row)\n",
    "    \n",
    "    return pd.DataFrame.from_records(records)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steady state test calculations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def grn_ode(t, y, params, p_on_eff=None):\n",
    "#     # Unpack species\n",
    "#     gene_1_A, gene_1_I, mRNA_1, protein_1, gene_2_A, gene_2_I, mRNA_2, protein_2 = y\n",
    "\n",
    "#     # Unpack parameters\n",
    "#     p_on_1 = params['{p_on_gene_1}']\n",
    "#     p_off_1 = params['{p_off_gene_1}']\n",
    "#     p_prod_mRNA_1 = params['{p_prod_mRNA_gene_1}']\n",
    "#     p_deg_mRNA_1 = params['{p_deg_mRNA_gene_1}']\n",
    "#     p_prod_protein_1 = params['{p_prod_protein_gene_1}']\n",
    "#     p_deg_protein_1 = params['{p_deg_protein_gene_1}']\n",
    "\n",
    "#     p_on_2 = params['{p_on_gene_2}']\n",
    "#     p_off_2 = params['{p_off_gene_2}']\n",
    "#     p_prod_mRNA_2 = params['{p_prod_mRNA_gene_2}']\n",
    "#     p_deg_mRNA_2 = params['{p_deg_mRNA_gene_2}']\n",
    "#     p_prod_protein_2 = params['{p_prod_protein_gene_2}']\n",
    "#     p_deg_protein_2 = params['{p_deg_protein_gene_2}']\n",
    "\n",
    "#     r_add = params['{p_add_gene_1_to_gene_2}']\n",
    "#     n = params['{n_gene_1_to_gene_2}']\n",
    "#     k = params['{k_gene_1_to_gene_2}']\n",
    "\n",
    "#     # Hill function (if p_on_eff is not provided)\n",
    "#     if p_on_eff is None:\n",
    "#         hill = (r_add * (protein_1**n)) / (k**n + protein_1**n)\n",
    "#         p_on2_eff = p_on_2 + hill\n",
    "#     else:\n",
    "#         p_on2_eff = p_on_eff\n",
    "\n",
    "#     # ODEs\n",
    "#     d_gene_1_A = -p_off_1 * gene_1_A + p_on_1 * gene_1_I\n",
    "#     d_gene_1_I = -d_gene_1_A\n",
    "\n",
    "#     d_mRNA_1 = p_prod_mRNA_1 * gene_1_A - p_deg_mRNA_1 * mRNA_1\n",
    "#     d_protein_1 = p_prod_protein_1 * mRNA_1 - p_deg_protein_1 * protein_1\n",
    "\n",
    "#     d_gene_2_A = -p_off_2 * gene_2_A + p_on2_eff * gene_2_I\n",
    "#     d_gene_2_I = -d_gene_2_A\n",
    "\n",
    "#     d_mRNA_2 = p_prod_mRNA_2 * gene_2_A - p_deg_mRNA_2 * mRNA_2\n",
    "#     d_protein_2 = p_prod_protein_2 * mRNA_2 - p_deg_protein_2 * protein_2\n",
    "\n",
    "#     return [\n",
    "#         d_gene_1_A, d_gene_1_I, d_mRNA_1, d_protein_1,\n",
    "#         d_gene_2_A, d_gene_2_I, d_mRNA_2, d_protein_2\n",
    "#     ]\n",
    "\n",
    "# def compute_effective_kon(df, param_dict):\n",
    "#     protein1 = df['gene_1_protein'].values\n",
    "#     n = float(param_dict['{n_gene_1_to_gene_2}'])\n",
    "#     k = float(param_dict['{k_gene_1_to_gene_2}'])\n",
    "#     p_add = float(param_dict['{p_add_gene_1_to_gene_2}'])\n",
    "#     p_on = float(param_dict['{p_on_gene_2}'])\n",
    "\n",
    "#     hill_vals = (protein1 ** n) / (k**n + protein1 ** n)\n",
    "#     return p_on + p_add * np.mean(hill_vals)\n",
    "\n",
    "\n",
    "\n",
    "# from scipy.integrate import solve_ivp\n",
    "\n",
    "# # Example parameters\n",
    "\n",
    "# # Initial conditions: all zeros except one active burst\n",
    "# y0 = population_0 # [A1, I1, m1, p1, A2, I2, m2, p2]\n",
    "\n",
    "# sim_Gillespie_10000_cells = pd.read_csv('/home/mzo5929/Keerthana/grnInference/simulation_data/gillespie_simulation/test/df_simulation_10000_cells_300h_timepoints_rows_12_13_20250701_213952_e87c9e5a.csv')\n",
    "# time = 299\n",
    "# singleTime_df_gillespie_10000 = sim_Gillespie_10000_cells[(sim_Gillespie_10000_cells['time_step'] == time)]\n",
    "# p_on_eff_gene_2 = compute_effective_kon(singleTime_df_gillespie_10000, full_param_dict)\n",
    "# protein1_samples = singleTime_df_gillespie_10000['gene_1_protein'].values\n",
    "# K = full_param_dict['{k_gene_1_to_gene_2}']\n",
    "# n = full_param_dict['{n_gene_1_to_gene_2}']\n",
    "# hill_vals = (protein1_samples ** n) / (K**n + protein1_samples ** n)\n",
    "# mean_hill = np.mean(hill_vals)\n",
    "# print(f\"Expected Hill output from simulation: {mean_hill:.4f}\")\n",
    "# hill_at_mean = (np.mean(protein1_samples) ** n) / (K**n + np.mean(protein1_samples) ** n)\n",
    "# print(f\"Hill(mean protein1): {hill_at_mean:.4f}\")\n",
    "\n",
    "\n",
    "# # from functools import partial\n",
    "# # from scipy.integrate import solve_ivp\n",
    "\n",
    "# # wrapped_ode = partial(grn_ode, params=full_param_dict, p_on_eff=p_on_eff_gene_2)\n",
    "# # sol = solve_ivp(wrapped_ode, [0, 1000], y0, method='RK45', dense_output=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate initial conditions from the low-res simulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_initial_condition(path_to_low_res_sim, species_index):\n",
    "    sim = pd.read_csv(path_to_low_res_sim)\n",
    "    max_time = sim['timestep'].max()\n",
    "    final_snapshot = sim[sim['timestep'] == max_time]\n",
    "\n",
    "    # Rename columns to match species_index\n",
    "    sim = final_snapshot.rename(columns={\n",
    "        \"gene_1_is_bursting\": \"gene_1_A\",\n",
    "        \"gene_1_unspliced_mRNA\": \"gene_1_mRNA\",\n",
    "        \"gene_2_is_bursting\": \"gene_2_A\",\n",
    "        \"gene_2_unspliced_mRNA\": \"gene_2_mRNA\"\n",
    "    })\n",
    "\n",
    "    init_conditions = []\n",
    "\n",
    "    for _, row in sim.iterrows():\n",
    "        state = np.zeros(len(species_index))\n",
    "\n",
    "        for name, idx in species_index.items():\n",
    "            if name.endswith(\"_I\"):  # Infer inactive state as 1 - active\n",
    "                active_name = name.replace(\"_I\", \"_A\")\n",
    "                state[idx] = 1 - row[active_name]\n",
    "            else:\n",
    "                state[idx] = row[name]\n",
    "\n",
    "        init_conditions.append(state)\n",
    "\n",
    "    return init_conditions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_matrix = \"/home/mzo5929/Keerthana/grnInference/simulation_data/general_simulation_data/test_data/matrix101.txt\"\n",
    "n_genes, interaction_matrix = read_input_matrix(path_to_matrix)\n",
    "interaction_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "reactions_df, gene_list = generate_reaction_network_from_matrix(interaction_matrix=interaction_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_states = generate_initial_state_from_genes(gene_list=gene_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_path = \"/home/mzo5929/Keerthana/grnInference/simulation_data/general_simulation_data/test_data/parameter_sheet_gillespie.csv\"\n",
    "rows = [12, 13]\n",
    "param_dict, param_df = assign_parameters_to_genes(param_path, gene_list, rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'{p_on_gene_1}': 0.4023188424412684, '{p_off_gene_1}': 69.57850258396365, '{p_prod_protein_gene_1}': 0.0297124846722611, '{p_prod_mRNA_gene_1}': 2080.5819902587614, '{p_deg_mRNA_gene_1}': 0.1395319074418133, '{p_deg_protein_gene_1}': 0.03957606697815643, '{p_on_gene_2}': 0.2127851341068382, '{p_off_gene_2}': 31.93368390579621, '{p_prod_protein_gene_2}': 0.1460875043611262, '{p_prod_mRNA_gene_2}': 2531.8584037063533, '{p_deg_mRNA_gene_2}': 0.12492856661168084, '{p_deg_protein_gene_2}': 0.007806136040099727, '{n_gene_1_to_gene_2}': 4.4118197399108965, '{p_add_gene_1_to_gene_2}': 2.0}\n",
      "gene_1 gene_1_to_gene_2 2.0 1 1.0\n"
     ]
    }
   ],
   "source": [
    "p_add_matrix = np.array([\n",
    "    [0.0, 2.0],  # gene_1 effects\n",
    "    [0, 0]  # gene_2 effects\n",
    "])\n",
    "\n",
    "n_matrix = np.array([\n",
    "    [0.0, 4.4118197399108965],  # gene_1 effects\n",
    "    [0, 0]  # gene_2 effects\n",
    "])\n",
    "\n",
    "steady_state, full_param_dict = add_interaction_terms(param_dict, interaction_matrix, gene_list, p_add_matrix=p_add_matrix, n_matrix = n_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'{p_on_gene_1}': 0.4023188424412684,\n",
       " '{p_off_gene_1}': 69.57850258396365,\n",
       " '{p_prod_protein_gene_1}': 0.0297124846722611,\n",
       " '{p_prod_mRNA_gene_1}': 2080.5819902587614,\n",
       " '{p_deg_mRNA_gene_1}': 0.1395319074418133,\n",
       " '{p_deg_protein_gene_1}': 0.03957606697815643,\n",
       " '{p_on_gene_2}': 0.2127851341068382,\n",
       " '{p_off_gene_2}': 31.93368390579621,\n",
       " '{p_prod_protein_gene_2}': 0.1460875043611262,\n",
       " '{p_prod_mRNA_gene_2}': 2531.8584037063533,\n",
       " '{p_deg_mRNA_gene_2}': 0.12492856661168084,\n",
       " '{p_deg_protein_gene_2}': 0.007806136040099727,\n",
       " '{n_gene_1_to_gene_2}': 4.4118197399108965,\n",
       " '{p_add_gene_1_to_gene_2}': 2.0,\n",
       " '{k_gene_1_to_gene_2}': 64.35895431409467}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_param_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_0, update_matrix, update_propensity_func_string, species_index = setup_gillespie_params_from_reactions(init_states, reactions_df, full_param_dict)\n",
    "exec(update_propensity_func_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_low_res_sim = '/home/mzo5929/Keerthana/grnInference/simulation_data/general_simulation_data/test/simulation_matrix101_A_B_12_13_fifteen_second_step_no_splicing_500h.csv'\n",
    "population_init_list = generate_initial_condition(path_to_low_res_sim, species_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    2, ..., 1997, 1998, 1999])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path_to_low_res_sim)\n",
    "df['cell_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "population_init_list length: 10000, n_cells: 20000\n",
      "population_init_list length: 10000, n_cells: 20000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "397fb00fa2c74d2ab58cf1f796afef9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 39\u001b[0m\n\u001b[1;32m     36\u001b[0m     population_init_list \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39msample(population_init_list, n_cells)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpopulation_init_list length: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(population_init_list)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, n_cells: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_cells\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 39\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_simulation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpop0\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpop0\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpopulation_init_list\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_cells\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, res \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(results):\n\u001b[1;32m     44\u001b[0m     samples[i, :, :] \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[0;32m~/.conda/envs/grnSimulationQuest/lib/python3.11/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/grnSimulationQuest/lib/python3.11/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/grnSimulationQuest/lib/python3.11/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Seed random number generator for reproducibility\n",
    "np.random.seed(42)\n",
    "n_gene = len(gene_list)\n",
    "n_cells = 20000\n",
    "time_duration = 300 #in hours\n",
    "time_points = np.arange(0, time_duration, 1)\n",
    "# Initialize output array\n",
    "# samples = np.empty((n_cells, len(time_points), n_gene*4), dtype=int)\n",
    "\n",
    "# Run the calculations\n",
    "# for i in tqdm(range(n_cells)):\n",
    "#     samples[i, :, :] = gillespie_ssa(update_propensities, update_matrix, population_0, time_points)\n",
    "    \n",
    "\n",
    "\n",
    "# Your original variables\n",
    "# samples: shape (n_cells, len(time_points), num_species)\n",
    "samples = np.zeros((n_cells, len(time_points), population_0.shape[0]))\n",
    "\n",
    "# def run_simulation(i):\n",
    "#     return gillespie_ssa(update_propensities, update_matrix, population_0, time_points)\n",
    "\n",
    "# # Run in parallel with tqdm\n",
    "# results = Parallel(n_jobs=5)(\n",
    "#     delayed(run_simulation)(i) for i in tqdm(range(n_cells))\n",
    "# )\n",
    "# # # Store results into the samples array\n",
    "# for i, res in enumerate(results):\n",
    "#     samples[i, :, :] = res\n",
    "\n",
    "def run_simulation(i, pop0):\n",
    "    return gillespie_ssa(update_propensities, update_matrix, pop0, time_points)\n",
    "\n",
    "print(f\"population_init_list length: {len(population_init_list)}, n_cells: {n_cells}\")\n",
    "if len(population_init_list) > n_cells:\n",
    "    population_init_list = random.sample(population_init_list, n_cells)\n",
    "print(f\"population_init_list length: {len(population_init_list)}, n_cells: {n_cells}\")\n",
    "\n",
    "results = Parallel(n_jobs=8)(\n",
    "    delayed(run_simulation)(i, pop0) for i, pop0 in tqdm(enumerate(population_init_list), total=n_cells)\n",
    ")\n",
    "\n",
    "for i, res in enumerate(results):\n",
    "    samples[i, :, :] = res\n",
    "\n",
    "all_samples = extract_mrna_protein(samples, species_index)\n",
    "\n",
    "\n",
    "#code to reshape 3D to 2D and output + input\n",
    "samples_reshaped = samples.reshape(samples.shape[0], -1)\n",
    "\n",
    "# === Setup ===\n",
    "now = datetime.now()\n",
    "timestamp_str = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "short_id = uuid.uuid4().hex[:8]\n",
    "row_str = \"_\".join(map(str, rows))\n",
    "prefix = f\"steady_state_init_15s_after_500h_{n_cells}_cells_{time_duration}h_timepoints_rows_{row_str}_{timestamp_str}_{short_id}\"\n",
    "\n",
    "base_path = \"/home/mzo5929/Keerthana/grnInference/simulation_data/gillespie_simulation/test\"\n",
    "jsonl_path = os.path.join(base_path, \"simulation_metadata.jsonl\")  # single file to append to\n",
    "\n",
    "# === File paths ===\n",
    "df_path = os.path.join(base_path, f\"df_simulation_{prefix}.csv\")\n",
    "samples_path = os.path.join(base_path, f\"samples_simulation_{prefix}.csv\")\n",
    "\n",
    "# === Save reshaped samples ===\n",
    "np.savetxt(samples_path, samples_reshaped, delimiter=\",\")\n",
    "\n",
    "# === Save DataFrame ===\n",
    "all_samples.to_csv(df_path, index=False)\n",
    "\n",
    "# === Prepare metadata record ===\n",
    "record = {\n",
    "    \"id\": short_id,\n",
    "    \"timestamp\": now.isoformat(),\n",
    "    \"param_dict\": param_dict,\n",
    "    \"interaction_matrix\": interaction_matrix.tolist(),\n",
    "    \"steady_state\": steady_state.tolist() if hasattr(steady_state, \"tolist\") else steady_state,\n",
    "    \"df_path\": df_path,\n",
    "    \"samples_path\": samples_path\n",
    "}\n",
    "\n",
    "# === Append to JSONL file ===\n",
    "with open(jsonl_path, 'a') as f:\n",
    "    f.write(json.dumps(record) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/mzo5929/Keerthana/grnInference/simulation_data/gillespie_simulation/test/df_simulation_steady_state_init_15s_after_500h_10000_cells_200h_timepoints_rows_12_13_20250704_171325_7b660e28.csv'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grnSimulationQuest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
